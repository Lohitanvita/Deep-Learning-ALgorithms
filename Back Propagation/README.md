Problem 1 (Practice of scalarâ€based backpropagation).
 You are required to calculate the gradients of  f(x,w) = 1/(2 + (torch.sin(x1*w1)**2) + torch.cos(x2*w2))
(a) Use computational graph for calculation 
(b) Based on(a), write a program to implement the computational graph 
and verify your answer in (a). 



Problem 2 (Practice of vectorâ€based backpropagation). 
You are required to calculate the gradients of f(X,W) = ||sigma(X,W)||^2 with respect to xi and Wi,j. 
Here â€–âˆ™â€–à¬¶ is the calculation of L2 loss, W is 3â€byâ€3 matrix and x is 3â€byâ€1 
vector, and ğœáˆºâˆ™áˆ» is sigmoid function that performs elementâ€wise sigmoid 
operation.  
(a) Use computational graph for calculation 
(b) Based on(a), write a program to implement the computational graph 
and verify your answer in (a). You can use vectorized approach to 
simply your codes. 

