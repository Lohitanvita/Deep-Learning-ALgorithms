1)  Evaluate  the  performance  of  different  types  of  optimizer  on  a  LeNet-5  network  using  
MNIST data. At least you need to evaluate SGD, AdaGrad, RMSprop. 

2)  Evaluate the performance of dropout on fully-connected layers and batch normalization 
on convolutional layers. The model is LeNet-5 on MNIST dataset. Among four options 1) 
FC  with  dropout,  CONV  with  BN;  2)  FC  with  dropout,  CONV  without  BN;  3)  FC  without  
dropout, CONV with BN; 4) FC without dropout, CONV without dropout, identify which one 
has the best performance? 
